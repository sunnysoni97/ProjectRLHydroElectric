{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.core.arrays.period import timedelta\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading train/validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('./data/train_data/train.xlsx')\n",
    "val = pd.read_excel('./data/val_data/validate.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping data and formatting dates (function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_avg_day(df):\n",
    "    if 'avg_day' not in df.columns:\n",
    "        df['avg_day']=df.iloc[:, 1:].mean(axis = 1)\n",
    "    else:\n",
    "        print(\"There's already a column avg_day! No need to create another one.\")\n",
    "        \n",
    "        \n",
    "def rename_prices(df):\n",
    "    if 'PRICES' in df.columns:\n",
    "        df.rename(columns={\"PRICES\": \"datetime\"}, inplace = True)\n",
    "    else:\n",
    "        print(\"There's no column PRICES.\")\n",
    "\n",
    "\n",
    "def dataformatting(df):\n",
    "    #wide to long\n",
    "    df = df.melt(id_vars=['datetime'], value_vars=df.columns[1:25]).sort_values(['datetime', 'variable'])\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    #creating master time column, ulgy but works\n",
    "    time = df['datetime'].copy()\n",
    "    for d in range(len(df['datetime'])):\n",
    "        time[d] = df['datetime'][d]+timedelta(hours = d%24) #decided not to go for the +1, so hour 1 is midnight, makes more sense, now it ends in 2009, otherwise the last measurement was 01.01.2010 00:00:00\n",
    "    df['time'] = time\n",
    "    \n",
    "    #hour from string to int\n",
    "    df['variable'] = df['variable'].map(lambda x:int(x[-2:]))\n",
    "    \n",
    "    #renaming, shullfing columns (not important)\n",
    "    df.rename(columns={\"datetime\": \"date\", \"variable\": \"hour\", \"value\":\"price\"}, inplace = True)\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_prices(train)\n",
    "rename_prices(val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretization functions for tabular q_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_col(in_df:pd.DataFrame,col_name:str,n_bins:int,band_length:float) -> pd.DataFrame:\n",
    "    out_df = in_df.copy()\n",
    "    max_band = band_length*n_bins\n",
    "    bins = np.linspace(0,max_band,n_bins)\n",
    "    bins = np.concatenate([bins,[np.inf]])\n",
    "    print(bins)\n",
    "    new_col = pd.cut(out_df[col_name],bins,labels=False,include_lowest=True)+1\n",
    "    out_df[col_name] = new_col\n",
    "    return out_df\n",
    "\n",
    "def create_df_discrete(in_df:pd.DataFrame, is_val:bool=False) -> pd.DataFrame:\n",
    "    out_df = dataformatting(in_df)\n",
    "    out_df['month'] = pd.DatetimeIndex(out_df['date']).month\n",
    "    #out_df['price_nondiscrete'] = out_df['price']\n",
    "    if(is_val):\n",
    "        out_df = discretize_col(out_df,'price',15,11)\n",
    "    else:\n",
    "        out_df = discretize_col(out_df,'price',15,10)\n",
    "    #return out_df[['price','hour','month','price_nondiscrete']]\n",
    "    return out_df[['price','hour','month']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating discrete dataframes and storing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.          10.71428571  21.42857143  32.14285714  42.85714286\n",
      "  53.57142857  64.28571429  75.          85.71428571  96.42857143\n",
      " 107.14285714 117.85714286 128.57142857 139.28571429 150.\n",
      "          inf]\n",
      "[  0.          11.78571429  23.57142857  35.35714286  47.14285714\n",
      "  58.92857143  70.71428571  82.5         94.28571429 106.07142857\n",
      " 117.85714286 129.64285714 141.42857143 153.21428571 165.\n",
      "          inf]\n"
     ]
    }
   ],
   "source": [
    "categorical_train = create_df_discrete(train)\n",
    "categorical_val = create_df_discrete(val,is_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     5129\n",
       "3     4655\n",
       "5     3818\n",
       "6     2725\n",
       "2     2270\n",
       "7     2133\n",
       "8     1676\n",
       "9     1099\n",
       "1      965\n",
       "10     623\n",
       "11     394\n",
       "12     316\n",
       "15     249\n",
       "13     143\n",
       "14     109\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_train['price'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       price  hour  month\n",
      "26299      4    20     12\n",
      "26300      3    21     12\n",
      "26301      3    22     12\n",
      "26302      3    23     12\n",
      "26303      3    24     12\n",
      "       price  hour  month\n",
      "17515      3    20     12\n",
      "17516      3    21     12\n",
      "17517      3    22     12\n",
      "17518      3    23     12\n",
      "17519      3    24     12\n"
     ]
    }
   ],
   "source": [
    "pprint(categorical_train.tail())\n",
    "pprint(categorical_val.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_discrete_path = os.path.join(os.getcwd(),'data/train_data/train_discrete.npy')\n",
    "val_discrete_path = os.path.join(os.getcwd(),'data/val_data/val_discrete.npy')\n",
    "\n",
    "with open(train_discrete_path,'wb') as f:\n",
    "    np.save(f,categorical_train.to_numpy())\n",
    "\n",
    "with open(val_discrete_path,'wb') as f:\n",
    "    np.save(f,categorical_val.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_rl_asgn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbabf998d7039075f5d858a6a5d1e46beb47c12201a23ca3f407e9b9517af609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
